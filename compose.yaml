version: "3.7"

services:
  caddy:
    image: caddy:alpine
    container_name: localai-caddy
    depends_on:
      tailscale:
        condition: service_healthy
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
      - tailscale_sock:/var/run/tailscale:ro
      - tailscale_tmp:/tmp:ro
    restart: unless-stopped
    network_mode: service:tailscale

  tailscale:
    image: tailscale/tailscale:v1.90.9
    container_name: localai-tailscale
    environment:
      - TS_HOSTNAME=localai                     # Your tailnet hostname
      - TS_AUTHKEY=${KEY}      # Your OAuth client key
      - TS_EXTRA_ARGS=--advertise-tags=tag:localai # Required for OAuth client
    extra_hosts:
      - "host.docker.internal:host-gateway"
    init: true
    healthcheck:  
      test: tailscale status --peers=false --json | grep 'Online.*true'
      start_period: 3s
      interval: 1s
      retries: 3
    restart: unless-stopped
    volumes:
      - ./tailscale-state:/var/lib/tailscale
      - tailscale_sock:/var/run/tailscale
      - tailscale_tmp:/tmp
    devices:
      - /dev/net/tun:/dev/net/tun
    cap_add:
      - NET_ADMIN
    networks:
      - localai
      # - sys_module

  python-api:
    build: ./backend
    image: localai-api
    container_name: localai-api
    depends_on:
      tailscale:
        condition: service_healthy
    networks: 
      - localai
    volumes:
      - ./users:/app/users
    restart: unless-stopped

  webapp:
    build: ./webbrowser
    container_name: localai-webapp
    depends_on:
      tailscale:
        condition: service_healthy
      python-api:
        condition: service_started
    networks: 
      - localai
    restart: unless-stopped

volumes:
  tailscale_sock:
  tailscale_tmp:
  caddy_data:
  caddy_config:

networks:
  localai:
    name: localai
    driver: bridge
